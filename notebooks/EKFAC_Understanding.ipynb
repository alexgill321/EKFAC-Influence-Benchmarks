{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0.7%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "import torch\n",
        "from src.linear_nn import get_model\n",
        "from src.model_eval import train_dataset\n",
        "\n",
        "\n",
        "# Load the model\n",
        "model = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FGiJ0k8v00qi"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import torch\n",
        "# class dataset(Dataset):\n",
        "#   def __init__(self,x,y):\n",
        "#     self.x = torch.tensor(x,dtype=torch.float32)\n",
        "#     self.y = torch.tensor(y,dtype=torch.float32)\n",
        "#     self.length = self.x.shape[0]\n",
        "\n",
        "#   def __getitem__(self,idx):\n",
        "#     return self.x[idx],self.y[idx]\n",
        "#   def __len__(self):\n",
        "#     return self.length\n",
        "# trainset = dataset(train_data, y_train)\n",
        "# queryset = dataset(test_data, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wuaaUbt97Ghg"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self,input_shape):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_shape,32)\n",
        "    self.fc2 = nn.Linear(32,64)\n",
        "    self.fc3 = nn.Linear(64,1)\n",
        "  def forward(self,x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kibxNxZR89YB"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "network = Net(x.shape[1])\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AKKZs6Py9Q3-"
      },
      "outputs": [],
      "source": [
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "class EKFACDistilled(Optimizer):\n",
        "    def __init__(self, net, eps):\n",
        "        self.eps = eps\n",
        "        self.params = []\n",
        "        self._fwd_handles = []\n",
        "        self._bwd_handles = []\n",
        "        self.net = net\n",
        "        for mod in net.modules():\n",
        "            mod_class = mod.__class__.__name__\n",
        "            if mod_class in ['Linear']:\n",
        "                handle = mod.register_forward_pre_hook(self._save_input)\n",
        "                self._fwd_handles.append(handle)\n",
        "                handle = mod.register_full_backward_hook(self._save_grad_output)\n",
        "                self._bwd_handles.append(handle)\n",
        "                params = [mod.weight]\n",
        "                if mod.bias is not None:\n",
        "                    params.append(mod.bias)\n",
        "                d = {'params': params, 'mod': mod, 'layer_type': mod_class, 'A': [], 'S': []}\n",
        "                self.params.append(d)\n",
        "        super(EKFACDistilled, self).__init__(self.params, {})\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            if len(group['params']) == 2:\n",
        "                weight, bias = group['params']\n",
        "            else:\n",
        "                weight = group['params'][0]\n",
        "                bias = None\n",
        "            state = self.state[weight]\n",
        "\n",
        "            self._compute_kfe(group, state)\n",
        "\n",
        "            self._precond(weight, bias, group, state)\n",
        "\n",
        "    def calc_cov(self, calc_act: bool = True):\n",
        "        for group in self.param_groups:\n",
        "            if len(group['params']) == 2:\n",
        "                weight, bias = group['params']\n",
        "            else:\n",
        "                weight = group['params'][0]\n",
        "                bias = None\n",
        "\n",
        "            state = self.state[weight]\n",
        "\n",
        "            mod = group['mod']\n",
        "            x = self.state[group['mod']]['x']\n",
        "            gy = self.state[group['mod']]['gy']\n",
        "\n",
        "            # Computation of activation cov matrix for batch\n",
        "            x = x.data.t()\n",
        "\n",
        "            # Append column of ones to x if bias is not None\n",
        "            if mod.bias is not None:\n",
        "                ones = torch.ones_like(x[:1])\n",
        "                x = torch.cat([x, ones], dim=0)\n",
        "            \n",
        "            if calc_act:\n",
        "                # Calculate covariance matrix for activations (A_{l-1})\n",
        "                A = torch.mm(x, x.t()) / float(x.shape[1])\n",
        "                group['A'].append(A)\n",
        "\n",
        "            # Computation of psuedograd of layer output cov matrix for batch\n",
        "            gy = gy.data.t()\n",
        "\n",
        "            # Calculate covariance matrix for layer outputs (S_{l})\n",
        "            S = torch.mm(gy, gy.t()) / float(gy.shape[1])\n",
        "\n",
        "            group['S'].append(S)\n",
        "\n",
        "    def _compute_kfe(self, group, state):\n",
        "        mod = group['mod']\n",
        "        x = self.state[group['mod']]['x']\n",
        "        gy = self.state[group['mod']]['gy']\n",
        "        \n",
        "        # Computation of xxt\n",
        "        x = x.data.t() # transpose of activations\n",
        "\n",
        "        # Append column of ones to x if bias is not None\n",
        "        if mod.bias is not None:\n",
        "            ones = torch.ones_like(x[:1])\n",
        "            x = torch.cat([x, ones], dim=0)\n",
        "\n",
        "        # Calculate covariance matrix for activations (A_{l-1})\n",
        "        xxt = torch.mm(x, x.t()) / float(x.shape[1])\n",
        "\n",
        "        # Calculate eigenvalues and eigenvectors of covariance matrix (lambdaA, QA)\n",
        "        la, state['Qa'] = torch.linalg.eigh(xxt, UPLO='U')\n",
        "\n",
        "        # Computation of ggt\n",
        "        gy = gy.data.t()\n",
        "\n",
        "        # Calculate covariance matrix for layer outputs (S_{l})\n",
        "        ggt = torch.mm(gy, gy.t()) / float(gy.shape[1])\n",
        "\n",
        "        # Calculate eigenvalues and eigenvectors of covariance matrix (lambdaS, QS)\n",
        "        ls, state['Qs'] = torch.linalg.eigh(ggt, UPLO='U')\n",
        "\n",
        "        # Outer product of the eigenvalue vectors. Of shape (len(s) x len(a))\n",
        "        state['m2'] = ls.unsqueeze(1) * la.unsqueeze(0)\n",
        "\n",
        "    def _precond(self, weight, bias, group, state):\n",
        "        \"\"\"Applies preconditioning.\"\"\"\n",
        "        Qa = state['Qa']\n",
        "        Qs = state['Qs']\n",
        "        m2 = state['m2']\n",
        "        x = self.state[group['mod']]['x']\n",
        "        gy = self.state[group['mod']]['gy']\n",
        "        g = weight.grad.data\n",
        "        s = g.shape\n",
        "        s_x = x.size()\n",
        "        s_gy = gy.size()\n",
        "        bs = x.size(0)\n",
        "\n",
        "        # Append column of ones to x if bias is not None\n",
        "        if bias is not None:\n",
        "            ones = torch.ones_like(x[:,:1])\n",
        "            x = torch.cat([x, ones], dim=1)\n",
        "        \n",
        "        # KFE of activations ??\n",
        "        x_kfe = torch.mm(x, Qa)\n",
        "\n",
        "        # KFE of layer outputs ??\n",
        "        gy_kfe = torch.mm(gy, Qs)\n",
        "\n",
        "        m2 = torch.mm(gy_kfe.t()**2, x_kfe**2) / bs\n",
        "\n",
        "        g_kfe = torch.mm(gy_kfe.t(), x_kfe) / bs\n",
        "\n",
        "        g_nat_kfe = g_kfe / (m2 + self.eps)\n",
        "\n",
        "        g_nat = torch.mm(g_nat_kfe, Qs.t())\n",
        "\n",
        "        if bias is not None:\n",
        "            gb = g_nat[:, -1].contiguous().view(*bias.shape)\n",
        "            bias.grad.data = gb\n",
        "            g_nat = g_nat[:, :-1]\n",
        "        \n",
        "        g_nat = g_nat.contiguous().view(*s)\n",
        "        weight.grad.data = g_nat\n",
        "\n",
        "    def _save_input(self, mod, i):\n",
        "        \"\"\"Saves input of layer to compute covariance.\"\"\"\n",
        "        self.state[mod]['x'] = i[0]\n",
        "\n",
        "    def _save_grad_output(self, mod, grad_input, grad_output):\n",
        "        \"\"\"Saves grad on output of layer to compute covariance.\"\"\"\n",
        "        self.state[mod]['gy'] = grad_output[0] * grad_output[0].size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import captum._utils.common as common\n",
        "from captum.influence._core.influence import DataInfluence\n",
        "from torch.nn import Module\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "from torch import Tensor\n",
        "import torch.distributions as dist\n",
        "\n",
        "\n",
        "class EKFACInfluence(DataInfluence):\n",
        "    def __init__(\n",
        "        self,\n",
        "        module: Module,\n",
        "        layers: Union[str, List[str]],\n",
        "        influence_src_dataset: Dataset,\n",
        "        activation_dir: str,\n",
        "        model_id: str = \"\",\n",
        "        batch_size: int = 1,\n",
        "        query_batch_size: int = 1,\n",
        "        **kwargs: Any,\n",
        "    ) -> None:\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            module (Module): An instance of pytorch model. This model should define all of its\n",
        "                layers as attributes of the model. The output of the model must be logits for the\n",
        "                classification task.\n",
        "            layers (Union[str, List[str]]): A list of layer names for which the influence will\n",
        "                be computed.\n",
        "            influence_src_dataset (torch.utils.data.Dataset): Pytorch dataset that is used to create\n",
        "                a pytorch dataloader to iterate over the dataset. This is the dataset for which we will\n",
        "                be seeking for influential instances. In most cases this is the training dataset.\n",
        "            activation_dir (str): Path to the directory where the activation computations will be stored.\n",
        "            model_id (str): The name/version of the model for which layer activations are being computed.\n",
        "                Activations will be stored and loaded under the subdirectory with this name if provided.\n",
        "            batch_size (int): Batch size for the dataloader used to iterate over the influence_src_dataset.\n",
        "            **kwargs: Any additional arguments that are necessary for specific implementations of the\n",
        "                'DataInfluence' abstract class.\n",
        "        \"\"\"\n",
        "        self.module = module\n",
        "        self.layers = [layers] if isinstance(layers, str) else layers\n",
        "        self.influence_src_dataset = influence_src_dataset\n",
        "        self.activation_dir = activation_dir\n",
        "        self.model_id = model_id\n",
        "        self.batch_size = batch_size\n",
        "        self.query_batch_size = query_batch_size\n",
        "\n",
        "        self.influence_src_dataloader = DataLoader(\n",
        "            self.influence_src_dataset, batch_size=batch_size, shuffle=False\n",
        "        )\n",
        "    \n",
        "    def influence(\n",
        "            self,\n",
        "            inputs: Dataset,\n",
        "            topk: int = 1,\n",
        "            additional_forward_args: Optional[Any] = None,\n",
        "            load_src_from_disk: bool = True,\n",
        "            **kwargs: Any,\n",
        "        ) -> Dict:\n",
        "\n",
        "        inputs_batch_size = (\n",
        "            inputs[0].shape[0] if isinstance(inputs, tuple) else inputs.shape[0]\n",
        "        )\n",
        "\n",
        "        influences: Dict[str, Any] = {}\n",
        "        query_grads: Dict[str, List[Tensor]] = {}\n",
        "        influence_src_grads: Dict[str, List[Tensor]] = {}\n",
        "\n",
        "        query_dataloader = DataLoader(\n",
        "            inputs, batch_size=self.query_batch_size, shuffle=False\n",
        "        )\n",
        "\n",
        "        layer_modules = [\n",
        "            common._get_module_from_name(self.module, layer) for layer in self.layers\n",
        "        ]\n",
        "\n",
        "        G_list = self._compute_EKFAC_GNH()\n",
        "\n",
        "        for i, (queries, targets) in enumerate(query_dataloader):\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            self.module.zero_grad()\n",
        "            queries, targets = inputs\n",
        "            outputs = self.module(queries)\n",
        "            loss = criterion(outputs, targets.view(-1))\n",
        "            loss.backward()\n",
        "\n",
        "            for layer in layer_modules:\n",
        "                if layer.bias is not None:\n",
        "                    grad_bias = layer.bias.grad\n",
        "                    grad_weights = layer.weight.grad\n",
        "                    grads = torch.cat([grad_weights.view(-1), grad_bias.view(-1)], dim=1)\n",
        "                else:\n",
        "                    grads = layer.weight.grad.view(-1)\n",
        "                for grad in grads:\n",
        "                    query_grads[layer].append(grad)\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(self.influence_src_dataloader):\n",
        "            self.module.zero_grad()\n",
        "            outputs = self.module(inputs)\n",
        "            loss = criterion(outputs, targets.view(-1))\n",
        "            loss.backward()\n",
        "\n",
        "            for layer in layer_modules:\n",
        "                if layer.bias is not None:\n",
        "                    grad_bias = layer.bias.grad\n",
        "                    grad_weights = layer.weight.grad\n",
        "                    grads = torch.cat([grad_weights.view(-1), grad_bias.view(-1)], dim=1)\n",
        "                else:\n",
        "                    grads = layer.weight.grad.view(-1)\n",
        "                for grad in grads:\n",
        "                    influence_src_grads[layer].append(grad)\n",
        "        \n",
        "        for layer in layer_modules:\n",
        "            query_grads[layer] = torch.stack(query_grads[layer])\n",
        "            influence_src_grads[layer] = torch.stack(influence_src_grads[layer])\n",
        "            influences[layer] = torch.matmul(influence_src_grads[layer], torch.matmul(G_list[layer], query_grads[layer]).t())\n",
        "\n",
        "        return influences\n",
        "            \n",
        "\n",
        "    def _compute_EKFAC_GNH(self, n_samples: int = 2):\n",
        "        ekfac = EKFACDistilled(self.module, 1e-5)\n",
        "        loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
        "        for i, (input, _) in enumerate(self.influence_src_dataloader):\n",
        "            outputs = self.module(input)\n",
        "            output_probs = torch.softmax(outputs, dim=-1)\n",
        "            distribution = dist.Categorical(output_probs)\n",
        "            for j in range(n_samples):\n",
        "                samples = distribution.sample()\n",
        "                loss = loss_fn(outputs, samples)\n",
        "                loss.backward()\n",
        "                ekfac.step()\n",
        "                self.module.zero_grad()\n",
        "        \n",
        "        G_list = []\n",
        "        # Compute average A and S\n",
        "        for group in ekfac.param_groups:\n",
        "            A = torch.stack(group['A']).mean(dim=0)\n",
        "            S = torch.stack(group['S']).mean(dim=0)\n",
        "        \n",
        "            # Compute eigenvalues and eigenvectors of A and S\n",
        "            la, Qa = torch.linalg.eigh(A, UPLO='U')\n",
        "            ls, Qs = torch.linalg.eigh(S, UPLO='U')\n",
        "\n",
        "            # Compute Kronecker product of eigenvalues and eigenvectors\n",
        "            eigenvec_kron = torch.kron(Qa, Qs)\n",
        "\n",
        "            eigenval_kron = torch.kron(torch.diag(la),torch.diag(ls))\n",
        "\n",
        "            # Compute GNH\n",
        "            G_list.append(torch.matmul(eigenvec_kron, torch.matmul(eigenval_kron, eigenvec_kron.t())))\n",
        "            \n",
        "        return G_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcuk4RoJ9dIM",
        "outputId": "6096bb71-01cb-4934-e929-35ed660117e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net\n",
            "**********************\n",
            "Linear\n",
            "**********************\n",
            "Linear\n",
            "**********************\n",
            "Linear\n",
            "**********************\n"
          ]
        }
      ],
      "source": [
        "precond = EKFACDistilled(network, eps=0.001)\n",
        "influence = EKFACInfluence(network, layers=['fc1', 'fc2'], influence_src_dataset=trainset, activation_dir='activations', model_id='test', batch_size=64, query_batch_size=32)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for mod in network.modules():\n",
        "  mod_class = mod.__class__.__name__\n",
        "  print(mod_class)\n",
        "  print(\"**********************\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the GNH Estimation using EKFACInfluence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (32x31 and 32x32)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\alexg\\Documents\\GitHub\\EKFAC-Influence-Benchmarks\\notebooks\\EKFAC_Understanding.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m G_list \u001b[39m=\u001b[39m influence\u001b[39m.\u001b[39;49m_compute_EKFAC_GNH(n_samples\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
            "\u001b[1;32mc:\\Users\\alexg\\Documents\\GitHub\\EKFAC-Influence-Benchmarks\\notebooks\\EKFAC_Understanding.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m         loss \u001b[39m=\u001b[39m loss_fn(outputs, samples)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m         loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m         ekfac\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m G_list \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32mc:\\Users\\alexg\\miniconda3\\envs\\captum_dev\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
            "\u001b[1;32mc:\\Users\\alexg\\Documents\\GitHub\\EKFAC-Influence-Benchmarks\\notebooks\\EKFAC_Understanding.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[weight]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_kfe(group, state)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_precond(weight, bias, group, state)\n",
            "\u001b[1;32mc:\\Users\\alexg\\Documents\\GitHub\\EKFAC-Influence-Benchmarks\\notebooks\\EKFAC_Understanding.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m g_kfe \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(gy_kfe\u001b[39m.\u001b[39mt(), x_kfe) \u001b[39m/\u001b[39m bs\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m g_nat_kfe \u001b[39m=\u001b[39m g_kfe \u001b[39m/\u001b[39m (m2 \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m g_nat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmm(g_nat_kfe, Qs\u001b[39m.\u001b[39;49mt())\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X14sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     gb \u001b[39m=\u001b[39m g_nat[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39mbias\u001b[39m.\u001b[39mshape)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x31 and 32x32)"
          ]
        }
      ],
      "source": [
        "G_list = influence._compute_EKFAC_GNH(n_samples=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YmB6iG_9dyA",
        "outputId": "7e70ef48-d35e-4646-8792-77ffcb4dbdcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Shape: torch.Size([60, 30])\n",
            "tensor([[ 1.0971, -2.0733,  1.2699,  ...,  2.2961,  2.7506,  1.9370],\n",
            "        [ 1.8298, -0.3536,  1.6860,  ...,  1.0871, -0.2439,  0.2812],\n",
            "        [ 1.5799,  0.4562,  1.5665,  ...,  1.9550,  1.1523,  0.2014],\n",
            "        ...,\n",
            "        [ 0.1655,  0.5353,  0.1475,  ...,  1.0475,  1.2898,  1.4106],\n",
            "        [-0.3060,  0.0047, -0.3855,  ..., -1.5759, -0.7470, -1.1668],\n",
            "        [-1.5647, -1.7452, -1.5499,  ..., -1.0722,  0.5165,  0.3499]])\n",
            "Target Shape: torch.Size([60])\n",
            "Output Shape: torch.Size([60, 1])\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'EKFACDistilled' object has no attribute 'calculate_cov'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\alexg\\Documents\\GitHub\\EKFAC-Influence-Benchmarks\\notebooks\\EKFAC_Understanding.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, samples)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m precond\u001b[39m.\u001b[39;49mcalculate_cov(calc_act\u001b[39m=\u001b[39mcalc_act)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m network\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexg/Documents/GitHub/EKFAC-Influence-Benchmarks/notebooks/EKFAC_Understanding.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m calc_act \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'EKFACDistilled' object has no attribute 'calculate_cov'"
          ]
        }
      ],
      "source": [
        "import torch.distributions as dist\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "n_samples = 2\n",
        "for i, (inputs, targets) in enumerate(trainloader):\n",
        "  optimizer.zero_grad\n",
        "  print(f'Input Shape: {inputs.shape}')\n",
        "  print(inputs)\n",
        "  print(f'Target Shape: {targets.shape}')\n",
        "  outputs = network(inputs)\n",
        "  print(f'Output Shape: {outputs.shape}')\n",
        "  output_probs = torch.softmax(outputs, dim=-1)\n",
        "  distribution = dist.Categorical(output_probs)\n",
        "  calc_act = True\n",
        "  for j in range(n_samples):\n",
        "    samples = distribution.sample()\n",
        "    loss = loss_fn(outputs, samples)\n",
        "    loss.backward(retain_graph=True)\n",
        "    precond.calculate_cov(calc_act=calc_act)\n",
        "    network.zero_grad()\n",
        "    calc_act = False\n",
        "  #loss = criterion(outputs, targets.reshape(-1,1))\n",
        "  #loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=30, out_features=32, bias=True)\n",
            "Activation Cov Matrix len: 10\n",
            "[0.8272504210472107, 0.22340252995491028, 0.824838399887085, 0.7830191254615784, 0.0704726055264473]\n",
            "[1.0926154851913452, 0.41147610545158386, 1.098839521408081, 1.0061488151550293, 0.026723619550466537]\n",
            "[0.8906545042991638, 0.3817518949508667, 0.8857139348983765, 0.8572977185249329, 0.1744510531425476]\n",
            "[1.4418561458587646, 0.562223494052887, 1.435240387916565, 1.5619181394577026, 0.19939666986465454]\n",
            "Output Cov Matrix len: 20\n",
            "Activation Cov Matrix shape: torch.Size([31, 31])\n",
            "Output Cov Matrix shape: torch.Size([32, 32])\n",
            "Linear(in_features=32, out_features=64, bias=True)\n",
            "Activation Cov Matrix len: 10\n",
            "[0.09568451344966888, 0.014156293123960495, 0.09352162480354309, 0.012460540048778057, 0.059680547565221786]\n",
            "[0.17700529098510742, 0.04611698165535927, 0.13976630568504333, 0.0574762187898159, 0.07323087006807327]\n",
            "[0.18632617592811584, 0.039563439786434174, 0.13833092153072357, 0.024181123822927475, 0.1765521615743637]\n",
            "[0.07058145850896835, 0.023563329130411148, 0.05690966546535492, 0.005692372564226389, 0.07210123538970947]\n",
            "Output Cov Matrix len: 20\n",
            "Activation Cov Matrix shape: torch.Size([33, 33])\n",
            "Output Cov Matrix shape: torch.Size([64, 64])\n",
            "Linear(in_features=64, out_features=1, bias=True)\n",
            "Activation Cov Matrix len: 10\n",
            "[0.018378132954239845, 0.002891946816816926, 0.02438117377460003, 0.002100131008774042, 0.016252262517809868]\n",
            "[0.014273939654231071, 0.002608750481158495, 0.018601106479763985, 0.0029885112307965755, 0.01397517416626215]\n",
            "[0.019208768382668495, 0.006254313513636589, 0.024044787511229515, 0.0019855606369674206, 0.013708183541893959]\n",
            "[0.038016900420188904, 0.0034088832326233387, 0.041364267468452454, 0.004512199200689793, 0.05113009735941887]\n",
            "Output Cov Matrix len: 20\n",
            "Activation Cov Matrix shape: torch.Size([65, 65])\n",
            "Output Cov Matrix shape: torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "for group in precond.param_groups:\n",
        "  print(group['mod'])\n",
        "  print(f'Activation Cov Matrix len: {len(group[\"A\"])}')\n",
        "  print(group['A'][0].tolist()[0][:5])\n",
        "  print(group['A'][1].tolist()[0][:5])\n",
        "  print(group['A'][2].tolist()[0][:5])\n",
        "  print(group['A'][3].tolist()[0][:5])\n",
        "  print(f'Output Cov Matrix len: {len(group[\"S\"])}')\n",
        "  print(f'Activation Cov Matrix shape: {group[\"A\"][0].shape}')\n",
        "  print(f'Output Cov Matrix shape: {group[\"S\"][0].shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0072457790374756, 0.31007063388824463, 1.0060679912567139, 0.9909204244613647, 0.1981646716594696]\n",
            "Averaged activation matrix: torch.Size([31, 31])\n",
            "Averaged output matrix: torch.Size([32, 32])\n",
            "[0.11650141328573227, 0.031128928065299988, 0.09232742339372635, 0.02067553624510765, 0.08652587234973907]\n",
            "Averaged activation matrix: torch.Size([33, 33])\n",
            "Averaged output matrix: torch.Size([64, 64])\n",
            "[0.02231888845562935, 0.00450670812278986, 0.026402030140161514, 0.0029004632961004972, 0.021502971649169922]\n",
            "Averaged activation matrix: torch.Size([65, 65])\n",
            "Averaged output matrix: torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "for group in precond.param_groups:\n",
        "    A = torch.stack(group['A']).mean(dim=0)\n",
        "    print(A.tolist()[0][:5])\n",
        "    S = torch.stack(group['S']).mean(dim=0)\n",
        "\n",
        "    print(f'Averaged activation matrix: {A.shape}')\n",
        "    print(f'Averaged output matrix: {S.shape}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
