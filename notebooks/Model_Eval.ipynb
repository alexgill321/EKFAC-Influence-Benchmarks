{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.linear_nn import get_model\n",
    "from src.model_eval import train_dataset\n",
    "from src.model_eval import noisy_examples, train_loader\n",
    "from torch.cpu.amp import autocast\n",
    "import psutil\n",
    "net, criterion, _, _ = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noisy_examples(train_loader, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "class EKFACDistilled(Optimizer):\n",
    "    def __init__(self, net, eps):\n",
    "        self.eps = eps\n",
    "        self.params = []\n",
    "        self._fwd_handles = []\n",
    "        self._bwd_handles = []\n",
    "        self.net = net\n",
    "        for mod in net.modules():\n",
    "            mod_class = mod.__class__.__name__\n",
    "            if mod_class in ['Linear']:\n",
    "                handle = mod.register_forward_pre_hook(self._save_input)\n",
    "                self._fwd_handles.append(handle)\n",
    "                handle = mod.register_full_backward_hook(self._save_grad_output)\n",
    "                self._bwd_handles.append(handle)\n",
    "                params = [mod.weight]\n",
    "                if mod.bias is not None:\n",
    "                    params.append(mod.bias)\n",
    "                d = {'params': params, 'mod': mod, 'layer_type': mod_class, 'A': [], 'S': []}\n",
    "                self.params.append(d)\n",
    "        super(EKFACDistilled, self).__init__(self.params, {})\n",
    "\n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            if len(group['params']) == 2:\n",
    "                weight, bias = group['params']\n",
    "            else:\n",
    "                weight = group['params'][0]\n",
    "                bias = None\n",
    "            state = self.state[weight]\n",
    "\n",
    "            self._compute_kfe(group, state)\n",
    "\n",
    "            self._precond(weight, bias, group, state)\n",
    "\n",
    "    def calc_cov(self, calc_act: bool = True):\n",
    "        for group in self.param_groups:\n",
    "            if len(group['params']) == 2:\n",
    "                weight, bias = group['params']\n",
    "            else:\n",
    "                weight = group['params'][0]\n",
    "                bias = None\n",
    "\n",
    "            state = self.state[weight]\n",
    "\n",
    "            mod = group['mod']\n",
    "            x = self.state[group['mod']]['x']\n",
    "            gy = self.state[group['mod']]['gy']\n",
    "\n",
    "            # Computation of activation cov matrix for batch\n",
    "            x = x.data.t()\n",
    "\n",
    "            # Append column of ones to x if bias is not None\n",
    "            if mod.bias is not None:\n",
    "                ones = torch.ones_like(x[:1])\n",
    "                x = torch.cat([x, ones], dim=0)\n",
    "            \n",
    "            if calc_act:\n",
    "                # Calculate covariance matrix for activations (A_{l-1})\n",
    "                A = torch.mm(x, x.t()) / float(x.shape[1])\n",
    "                group['A'].append(A)\n",
    "\n",
    "            # Computation of psuedograd of layer output cov matrix for batch\n",
    "            gy = gy.data.t()\n",
    "\n",
    "            # Calculate covariance matrix for layer outputs (S_{l})\n",
    "            S = torch.mm(gy, gy.t()) / float(gy.shape[1])\n",
    "\n",
    "            group['S'].append(S)\n",
    "\n",
    "    def _compute_kfe(self, group, state):\n",
    "        mod = group['mod']\n",
    "        x = self.state[group['mod']]['x']\n",
    "        gy = self.state[group['mod']]['gy']\n",
    "        \n",
    "        # Computation of xxt\n",
    "        x = x.data.t() # transpose of activations\n",
    "\n",
    "        # Append column of ones to x if bias is not None\n",
    "        if mod.bias is not None:\n",
    "            ones = torch.ones_like(x[:1])\n",
    "            x = torch.cat([x, ones], dim=0)\n",
    "\n",
    "        # Calculate covariance matrix for activations (A_{l-1})\n",
    "        xxt = torch.mm(x, x.t()) / float(x.shape[1])\n",
    "\n",
    "        # Calculate eigenvalues and eigenvectors of covariance matrix (lambdaA, QA)\n",
    "        la, state['Qa'] = torch.linalg.eigh(xxt, UPLO='U')\n",
    "\n",
    "        # Computation of ggt\n",
    "        gy = gy.data.t()\n",
    "\n",
    "        # Calculate covariance matrix for layer outputs (S_{l})\n",
    "        ggt = torch.mm(gy, gy.t()) / float(gy.shape[1])\n",
    "\n",
    "        # Calculate eigenvalues and eigenvectors of covariance matrix (lambdaS, QS)\n",
    "        ls, state['Qs'] = torch.linalg.eigh(ggt, UPLO='U')\n",
    "\n",
    "        # Outer product of the eigenvalue vectors. Of shape (len(s) x len(a))\n",
    "        state['m2'] = ls.unsqueeze(1) * la.unsqueeze(0)\n",
    "\n",
    "    def _precond(self, weight, bias, group, state):\n",
    "        \"\"\"Applies preconditioning.\"\"\"\n",
    "        Qa = state['Qa']\n",
    "        Qs = state['Qs']\n",
    "        m2 = state['m2']\n",
    "        x = self.state[group['mod']]['x']\n",
    "        gy = self.state[group['mod']]['gy']\n",
    "        g = weight.grad.data\n",
    "        s = g.shape\n",
    "        s_x = x.size()\n",
    "        s_gy = gy.size()\n",
    "        bs = x.size(0)\n",
    "\n",
    "        # Append column of ones to x if bias is not None\n",
    "        if bias is not None:\n",
    "            ones = torch.ones_like(x[:,:1])\n",
    "            x = torch.cat([x, ones], dim=1)\n",
    "        \n",
    "        # KFE of activations ??\n",
    "        x_kfe = torch.mm(x, Qa)\n",
    "\n",
    "        # KFE of layer outputs ??\n",
    "        gy_kfe = torch.mm(gy, Qs)\n",
    "\n",
    "        m2 = torch.mm(gy_kfe.t()**2, x_kfe**2) / bs\n",
    "\n",
    "        g_kfe = torch.mm(gy_kfe.t(), x_kfe) / bs\n",
    "\n",
    "        g_nat_kfe = g_kfe / (m2 + self.eps)\n",
    "\n",
    "        g_nat = torch.mm(g_nat_kfe, Qs.t())\n",
    "\n",
    "        if bias is not None:\n",
    "            gb = g_nat[:, -1].contiguous().view(*bias.shape)\n",
    "            bias.grad.data = gb\n",
    "            g_nat = g_nat[:, :-1]\n",
    "        \n",
    "        g_nat = g_nat.contiguous().view(*s)\n",
    "        weight.grad.data = g_nat\n",
    "\n",
    "    def _save_input(self, mod, i):\n",
    "        \"\"\"Saves input of layer to compute covariance.\"\"\"\n",
    "        self.state[mod]['x'] = i[0]\n",
    "\n",
    "    def _save_grad_output(self, mod, grad_input, grad_output):\n",
    "        \"\"\"Saves grad on output of layer to compute covariance.\"\"\"\n",
    "        self.state[mod]['gy'] = grad_output[0] * grad_output[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import captum._utils.common as common\n",
    "from captum.influence._core.influence import DataInfluence\n",
    "from torch.nn import Module\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from torch import Tensor\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class EKFACInfluence(DataInfluence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        module: Module,\n",
    "        layers: Union[str, List[str]],\n",
    "        influence_src_dataset: Dataset,\n",
    "        activation_dir: str,\n",
    "        model_id: str = \"\",\n",
    "        batch_size: int = 1,\n",
    "        query_batch_size: int = 1,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            module (Module): An instance of pytorch model. This model should define all of its\n",
    "                layers as attributes of the model. The output of the model must be logits for the\n",
    "                classification task.\n",
    "            layers (Union[str, List[str]]): A list of layer names for which the influence will\n",
    "                be computed.\n",
    "            influence_src_dataset (torch.utils.data.Dataset): Pytorch dataset that is used to create\n",
    "                a pytorch dataloader to iterate over the dataset. This is the dataset for which we will\n",
    "                be seeking for influential instances. In most cases this is the training dataset.\n",
    "            activation_dir (str): Path to the directory where the activation computations will be stored.\n",
    "            model_id (str): The name/version of the model for which layer activations are being computed.\n",
    "                Activations will be stored and loaded under the subdirectory with this name if provided.\n",
    "            batch_size (int): Batch size for the dataloader used to iterate over the influence_src_dataset.\n",
    "            **kwargs: Any additional arguments that are necessary for specific implementations of the\n",
    "                'DataInfluence' abstract class.\n",
    "        \"\"\"\n",
    "        self.module = module\n",
    "        self.layers = [layers] if isinstance(layers, str) else layers\n",
    "        self.influence_src_dataset = influence_src_dataset\n",
    "        self.activation_dir = activation_dir\n",
    "        self.model_id = model_id\n",
    "        self.batch_size = batch_size\n",
    "        self.query_batch_size = query_batch_size\n",
    "\n",
    "        self.influence_src_dataloader = DataLoader(\n",
    "            self.influence_src_dataset, batch_size=batch_size, shuffle=False\n",
    "        )\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    def influence(\n",
    "            self,\n",
    "            inputs: Dataset,\n",
    "            topk: int = 1,\n",
    "            additional_forward_args: Optional[Any] = None,\n",
    "            load_src_from_disk: bool = True,\n",
    "            eps: float = 1e-5,\n",
    "            **kwargs: Any,\n",
    "        ) -> Dict:\n",
    "\n",
    "        influences: Dict[str, Any] = {}\n",
    "        query_grads: Dict[str, List[Tensor]] = {}\n",
    "        influence_src_grads: Dict[str, List[Tensor]] = {}\n",
    "\n",
    "        query_dataloader = DataLoader(\n",
    "            inputs, batch_size=self.query_batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "        layer_modules = [\n",
    "            common._get_module_from_name(self.module, layer) for layer in self.layers\n",
    "        ]\n",
    "\n",
    "        G_list = self._compute_EKFAC_GNH()\n",
    "\n",
    "        for i, (queries, targets) in enumerate(query_dataloader):\n",
    "            criterion = torch.nn.NLLLoss(reduction='sum')\n",
    "            self.module.zero_grad()\n",
    "            queries, targets = inputs\n",
    "            print(f'Query shape {queries.shape}')\n",
    "            print(f'Target shape {targets.shape}')\n",
    "            outputs = self.module(queries)\n",
    "\n",
    "            print(f'Output shape {outputs.shape}')\n",
    "            loss = criterion(outputs, targets.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            for layer in layer_modules:\n",
    "                Qa = G_list[layer]['Qa']\n",
    "                Qs = G_list[layer]['Qs']\n",
    "                eigenval_diag = G_list[layer]['lambda']\n",
    "                if layer.bias is not None:\n",
    "                    grad_bias = layer.bias.grad\n",
    "                    grad_weights = layer.weight.grad\n",
    "                    grads = torch.cat([grad_weights.view(-1), grad_bias.view(-1)], dim=1)\n",
    "                else:\n",
    "                    grads = layer.weight.grad.view(-1)\n",
    "                for grad in grads:\n",
    "                    p1 = torch.matmul(Qs, torch.matmul(grad, Qa.t()))\n",
    "                    # TODO: fix p2 shape\n",
    "                    p2 = torch.reciprocal(eigenval_diag+eps).reshape(p1.shape[0], 1)\n",
    "                    ihvp = torch.flatten(torch.matmul(Qs.t(), torch.matmul(p1/p2), Qa))\n",
    "                    query_grads[layer].append(ihvp)\n",
    "\n",
    "\n",
    "                    \n",
    "        for i, (inputs, targets) in tqdm.tqdm(enumerate(self.influence_src_dataloader)):\n",
    "            self.module.zero_grad()\n",
    "            outputs = self.module(inputs)\n",
    "            loss = criterion(outputs, targets.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            for layer in layer_modules:\n",
    "                if layer.bias is not None:\n",
    "                    grad_bias = layer.bias.grad\n",
    "                    grad_weights = layer.weight.grad\n",
    "                    grads = torch.cat([grad_weights.view(-1), grad_bias.view(-1)], dim=1)\n",
    "                else:\n",
    "                    grads = layer.weight.grad.view(-1)\n",
    "                for grad in grads:\n",
    "                    influence_src_grads[layer].append(grad)\n",
    "        \n",
    "        for layer in layer_modules:\n",
    "            query_grads[layer] = torch.stack(query_grads[layer])\n",
    "            influence_src_grads[layer] = torch.stack(influence_src_grads[layer])\n",
    "            influences[layer] = torch.matmul(influence_src_grads[layer], torch.matmul(G_list[layer], query_grads[layer]).t())\n",
    "\n",
    "        return influences\n",
    "            \n",
    "\n",
    "    def _compute_EKFAC_params(self, n_samples: int = 2):\n",
    "        ekfac = EKFACDistilled(self.module, 1e-5)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "        for i, (input, _) in tqdm.tqdm(enumerate(self.influence_src_dataloader), total=len(self.influence_src_dataloader)):\n",
    "            outputs = self.module(input)\n",
    "            output_probs = torch.softmax(outputs, dim=-1)\n",
    "            distribution = dist.Categorical(output_probs)\n",
    "            for j in range(n_samples):\n",
    "                samples = distribution.sample()\n",
    "                loss = loss_fn(outputs, samples)\n",
    "                loss.backward(retain_graph=True)\n",
    "                ekfac.calc_cov()\n",
    "                self.module.zero_grad()\n",
    "        \n",
    "        G_list = {}\n",
    "        # Compute average A and S\n",
    "        for group in ekfac.param_groups:\n",
    "            G_list[group['mod']] = {}\n",
    "            with autocast():\n",
    "                A = torch.stack(group['A']).mean(dim=0)\n",
    "                S = torch.stack(group['S']).mean(dim=0)\n",
    "\n",
    "                print(f'Activation cov matrix shape {A.shape}')\n",
    "                print(f'Layer output cov matrix shape {S.shape}')\n",
    "            \n",
    "                # Compute eigenvalues and eigenvectors of A and S\n",
    "                la, Qa = torch.linalg.eigh(A, UPLO='U')\n",
    "                ls, Qs = torch.linalg.eigh(S, UPLO='U')\n",
    "\n",
    "                eigenval_diags = torch.outer(la, ls).flatten(start_dim=0)\n",
    "\n",
    "            G_list[group['mod']]['Qa'] = Qa\n",
    "            G_list[group['mod']]['Qs'] = Qs\n",
    "            G_list[group['mod']]['lambda'] = eigenval_diags\n",
    "            \n",
    "        return G_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN\n",
      "**********************\n",
      "Linear\n",
      "**********************\n",
      "Linear\n",
      "**********************\n"
     ]
    }
   ],
   "source": [
    "precond = EKFACDistilled(net, eps=0.001)\n",
    "influence = EKFACInfluence(net, layers=['fc1', 'fc2'], influence_src_dataset=train_dataset, activation_dir='activations', model_id='test', batch_size=64, query_batch_size=32)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for mod in net.modules():\n",
    "  mod_class = mod.__class__.__name__\n",
    "  print(mod_class)\n",
    "  print(\"**********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:14<00:00, 52.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation cov matrix shape torch.Size([785, 785])\n",
      "Layer output cov matrix shape torch.Size([82, 82])\n",
      "Activation cov matrix shape torch.Size([83, 83])\n",
      "Layer output cov matrix shape torch.Size([10, 10])\n",
      "{Linear(in_features=784, out_features=82, bias=True): {'Qa': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 5.2909e-01,  8.3673e-02,  1.2583e-01,  ..., -3.4459e-08,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.2680e-02,  4.9224e-02,  5.7036e-03,  ..., -4.9098e-08,\n",
      "         -8.0094e-08, -1.1921e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.1447e-04,\n",
      "         -4.6267e-02,  1.5386e-01]]), 'Qs': tensor([[-5.6683e-04, -9.0305e-05, -8.9813e-04,  ...,  1.4166e-02,\n",
      "          1.7369e-02, -1.5343e-02],\n",
      "        [-6.7579e-04,  1.2529e-03,  1.4962e-03,  ...,  7.7193e-03,\n",
      "         -3.0952e-03, -1.0180e-02],\n",
      "        [-4.1286e-04, -2.5941e-03, -7.8649e-03,  ..., -4.4033e-03,\n",
      "         -9.6762e-03, -1.3955e-02],\n",
      "        ...,\n",
      "        [-9.1214e-04,  9.6769e-05,  1.2985e-03,  ...,  1.1830e-02,\n",
      "         -5.7924e-03, -6.4871e-04],\n",
      "        [ 5.8838e-05,  4.8595e-04, -9.7745e-03,  ...,  3.3407e-02,\n",
      "          3.1498e-02, -6.1528e-02],\n",
      "        [ 5.3638e-04, -1.0210e-03,  1.5217e-02,  ...,  2.9947e-02,\n",
      "          8.5556e-02,  2.7664e-01]]), 'lambda': tensor([-1.1350e-08, -1.3525e-08, -9.3805e-08,  ...,  2.6020e+03,\n",
      "         2.6356e+03,  3.3837e+03])}, Linear(in_features=82, out_features=10, bias=True): {'Qa': tensor([[-1.2290e-03,  2.5141e-04, -6.0969e-03,  ..., -5.6451e-03,\n",
      "          1.3946e-02,  4.9348e-03],\n",
      "        [ 1.3267e-03, -7.5729e-04,  9.9898e-01,  ..., -1.7193e-03,\n",
      "         -5.7899e-05,  9.7370e-04],\n",
      "        [ 1.8841e-05, -2.4524e-04, -1.2044e-02,  ..., -9.2909e-03,\n",
      "          5.2551e-03,  4.0629e-03],\n",
      "        ...,\n",
      "        [-3.7032e-05, -1.1338e-04,  5.5960e-03,  ..., -1.5924e-02,\n",
      "          3.2217e-02,  2.3473e-02],\n",
      "        [ 2.7664e-04,  1.0996e-04,  9.7224e-04,  ..., -1.8521e-01,\n",
      "          9.3870e-02,  1.3924e-01],\n",
      "        [-1.8820e-05,  6.6565e-04, -6.3780e-03,  ...,  7.8754e-02,\n",
      "          1.7655e-01,  7.0670e-01]]), 'Qs': tensor([[-0.3162,  0.0143,  0.0304,  0.0584,  0.3088,  0.4849,  0.6651, -0.3216,\n",
      "         -0.1345, -0.0333],\n",
      "        [-0.3162,  0.0141,  0.0288,  0.0547,  0.2790,  0.2813, -0.7301, -0.4252,\n",
      "         -0.1546, -0.0368],\n",
      "        [-0.3162, -0.8185, -0.3230, -0.2166, -0.2698, -0.0340,  0.0164, -0.0547,\n",
      "         -0.0381, -0.0111],\n",
      "        [-0.3162,  0.1302,  0.6671, -0.5516, -0.3551, -0.0390,  0.0191, -0.0615,\n",
      "         -0.0424, -0.0123],\n",
      "        [-0.3162,  0.0100,  0.0193,  0.0344,  0.1455,  0.0547, -0.0349,  0.2104,\n",
      "          0.4197,  0.8078],\n",
      "        [-0.3162,  0.0565,  0.1504,  0.7478, -0.5520, -0.0479,  0.0226, -0.0709,\n",
      "         -0.0474, -0.0133],\n",
      "        [-0.3162,  0.5558, -0.6510, -0.2727, -0.2939, -0.0358,  0.0178, -0.0570,\n",
      "         -0.0398, -0.0118],\n",
      "        [-0.3162,  0.0163,  0.0347,  0.0668,  0.3956, -0.8152,  0.1276, -0.2110,\n",
      "         -0.1066, -0.0279],\n",
      "        [-0.3162,  0.0113,  0.0231,  0.0424,  0.1889,  0.0907, -0.0644,  0.7412,\n",
      "         -0.5419, -0.0808],\n",
      "        [-0.3162,  0.0100,  0.0202,  0.0364,  0.1531,  0.0603, -0.0393,  0.2502,\n",
      "          0.6854, -0.5806]]), 'lambda': tensor([1.6355e-10, 1.8033e-03, 1.8266e-03, 1.8707e-03, 1.9944e-03, 2.1745e-03,\n",
      "        2.2199e-03, 2.3163e-03, 2.4273e-03, 2.4952e-03, 2.0139e-10, 2.2206e-03,\n",
      "        2.2492e-03, 2.3035e-03, 2.4559e-03, 2.6776e-03, 2.7335e-03, 2.8523e-03,\n",
      "        2.9889e-03, 3.0726e-03, 3.2057e-09, 3.5346e-02, 3.5802e-02, 3.6666e-02,\n",
      "        3.9091e-02, 4.2621e-02, 4.3511e-02, 4.5401e-02, 4.7576e-02, 4.8908e-02,\n",
      "        7.6143e-09, 8.3957e-02, 8.5040e-02, 8.7092e-02, 9.2852e-02, 1.0124e-01,\n",
      "        1.0335e-01, 1.0784e-01, 1.1301e-01, 1.1617e-01, 8.8999e-09, 9.8133e-02,\n",
      "        9.9399e-02, 1.0180e-01, 1.0853e-01, 1.1833e-01, 1.2080e-01, 1.2605e-01,\n",
      "        1.3208e-01, 1.3578e-01, 1.1474e-08, 1.2652e-01, 1.2815e-01, 1.3124e-01,\n",
      "        1.3992e-01, 1.5256e-01, 1.5575e-01, 1.6251e-01, 1.7029e-01, 1.7506e-01,\n",
      "        1.3461e-08, 1.4843e-01, 1.5034e-01, 1.5397e-01, 1.6415e-01, 1.7897e-01,\n",
      "        1.8271e-01, 1.9065e-01, 1.9978e-01, 2.0537e-01, 1.4074e-08, 1.5518e-01,\n",
      "        1.5718e-01, 1.6097e-01, 1.7162e-01, 1.8711e-01, 1.9102e-01, 1.9932e-01,\n",
      "        2.0887e-01, 2.1471e-01, 1.5206e-08, 1.6766e-01, 1.6983e-01, 1.7392e-01,\n",
      "        1.8543e-01, 2.0217e-01, 2.0639e-01, 2.1536e-01, 2.2567e-01, 2.3199e-01,\n",
      "        1.5976e-08, 1.7616e-01, 1.7843e-01, 1.8274e-01, 1.9482e-01, 2.1241e-01,\n",
      "        2.1685e-01, 2.2627e-01, 2.3711e-01, 2.4375e-01, 1.8808e-08, 2.0738e-01,\n",
      "        2.1006e-01, 2.1513e-01, 2.2936e-01, 2.5006e-01, 2.5529e-01, 2.6638e-01,\n",
      "        2.7913e-01, 2.8695e-01, 2.0679e-08, 2.2801e-01, 2.3096e-01, 2.3653e-01,\n",
      "        2.5217e-01, 2.7494e-01, 2.8068e-01, 2.9287e-01, 3.0690e-01, 3.1550e-01,\n",
      "        2.1996e-08, 2.4253e-01, 2.4566e-01, 2.5159e-01, 2.6823e-01, 2.9245e-01,\n",
      "        2.9856e-01, 3.1152e-01, 3.2645e-01, 3.3559e-01, 2.5877e-08, 2.8532e-01,\n",
      "        2.8900e-01, 2.9598e-01, 3.1555e-01, 3.4404e-01, 3.5123e-01, 3.6648e-01,\n",
      "        3.8404e-01, 3.9479e-01, 2.9206e-08, 3.2204e-01, 3.2619e-01, 3.3406e-01,\n",
      "        3.5616e-01, 3.8831e-01, 3.9643e-01, 4.1364e-01, 4.3346e-01, 4.4559e-01,\n",
      "        3.0453e-08, 3.3578e-01, 3.4011e-01, 3.4832e-01, 3.7135e-01, 4.0488e-01,\n",
      "        4.1334e-01, 4.3129e-01, 4.5195e-01, 4.6461e-01, 3.2637e-08, 3.5986e-01,\n",
      "        3.6450e-01, 3.7330e-01, 3.9799e-01, 4.3392e-01, 4.4299e-01, 4.6223e-01,\n",
      "        4.8437e-01, 4.9793e-01, 3.8990e-08, 4.2991e-01, 4.3545e-01, 4.4596e-01,\n",
      "        4.7546e-01, 5.1838e-01, 5.2921e-01, 5.5220e-01, 5.7865e-01, 5.9485e-01,\n",
      "        4.0675e-08, 4.4849e-01, 4.5428e-01, 4.6524e-01, 4.9601e-01, 5.4079e-01,\n",
      "        5.5209e-01, 5.7607e-01, 6.0366e-01, 6.2056e-01, 4.6267e-08, 5.1015e-01,\n",
      "        5.1673e-01, 5.2919e-01, 5.6419e-01, 6.1514e-01, 6.2799e-01, 6.5526e-01,\n",
      "        6.8665e-01, 7.0587e-01, 5.1425e-08, 5.6702e-01, 5.7434e-01, 5.8819e-01,\n",
      "        6.2710e-01, 6.8372e-01, 6.9800e-01, 7.2832e-01, 7.6320e-01, 7.8457e-01,\n",
      "        5.3555e-08, 5.9050e-01, 5.9812e-01, 6.1255e-01, 6.5307e-01, 7.1203e-01,\n",
      "        7.2691e-01, 7.5848e-01, 7.9481e-01, 8.1706e-01, 5.4784e-08, 6.0406e-01,\n",
      "        6.1186e-01, 6.2662e-01, 6.6806e-01, 7.2838e-01, 7.4360e-01, 7.7589e-01,\n",
      "        8.1306e-01, 8.3582e-01, 5.5922e-08, 6.1661e-01, 6.2456e-01, 6.3963e-01,\n",
      "        6.8194e-01, 7.4351e-01, 7.5904e-01, 7.9201e-01, 8.2994e-01, 8.5318e-01,\n",
      "        5.9045e-08, 6.5105e-01, 6.5944e-01, 6.7536e-01, 7.2002e-01, 7.8503e-01,\n",
      "        8.0143e-01, 8.3624e-01, 8.7630e-01, 9.0083e-01, 6.1915e-08, 6.8269e-01,\n",
      "        6.9149e-01, 7.0818e-01, 7.5501e-01, 8.2318e-01, 8.4038e-01, 8.7688e-01,\n",
      "        9.1888e-01, 9.4461e-01, 6.4755e-08, 7.1400e-01, 7.2321e-01, 7.4066e-01,\n",
      "        7.8965e-01, 8.6095e-01, 8.7893e-01, 9.1711e-01, 9.6104e-01, 9.8794e-01,\n",
      "        6.5364e-08, 7.2072e-01, 7.3002e-01, 7.4763e-01, 7.9708e-01, 8.6905e-01,\n",
      "        8.8721e-01, 9.2574e-01, 9.7008e-01, 9.9724e-01, 6.7724e-08, 7.4674e-01,\n",
      "        7.5637e-01, 7.7462e-01, 8.2586e-01, 9.0042e-01, 9.1924e-01, 9.5916e-01,\n",
      "        1.0051e+00, 1.0332e+00, 6.9956e-08, 7.7135e-01, 7.8130e-01, 8.0015e-01,\n",
      "        8.5307e-01, 9.3009e-01, 9.4953e-01, 9.9076e-01, 1.0382e+00, 1.0673e+00,\n",
      "        7.3074e-08, 8.0573e-01, 8.1612e-01, 8.3581e-01, 8.9109e-01, 9.7155e-01,\n",
      "        9.9185e-01, 1.0349e+00, 1.0845e+00, 1.1149e+00, 7.4411e-08, 8.2047e-01,\n",
      "        8.3106e-01, 8.5111e-01, 9.0740e-01, 9.8933e-01, 1.0100e+00, 1.0539e+00,\n",
      "        1.1043e+00, 1.1353e+00, 7.8657e-08, 8.6728e-01, 8.7847e-01, 8.9967e-01,\n",
      "        9.5917e-01, 1.0458e+00, 1.0676e+00, 1.1140e+00, 1.1673e+00, 1.2000e+00,\n",
      "        8.0058e-08, 8.8274e-01, 8.9413e-01, 9.1570e-01, 9.7627e-01, 1.0644e+00,\n",
      "        1.0866e+00, 1.1338e+00, 1.1882e+00, 1.2214e+00, 8.3349e-08, 9.1903e-01,\n",
      "        9.3088e-01, 9.5334e-01, 1.0164e+00, 1.1082e+00, 1.1313e+00, 1.1805e+00,\n",
      "        1.2370e+00, 1.2716e+00, 8.6217e-08, 9.5065e-01, 9.6291e-01, 9.8615e-01,\n",
      "        1.0514e+00, 1.1463e+00, 1.1702e+00, 1.2211e+00, 1.2796e+00, 1.3154e+00,\n",
      "        9.3094e-08, 1.0265e+00, 1.0397e+00, 1.0648e+00, 1.1352e+00, 1.2377e+00,\n",
      "        1.2636e+00, 1.3185e+00, 1.3816e+00, 1.4203e+00, 9.6296e-08, 1.0618e+00,\n",
      "        1.0755e+00, 1.1014e+00, 1.1743e+00, 1.2803e+00, 1.3071e+00, 1.3638e+00,\n",
      "        1.4291e+00, 1.4692e+00, 9.7707e-08, 1.0773e+00, 1.0912e+00, 1.1176e+00,\n",
      "        1.1915e+00, 1.2991e+00, 1.3262e+00, 1.3838e+00, 1.4501e+00, 1.4907e+00,\n",
      "        9.9540e-08, 1.0976e+00, 1.1117e+00, 1.1385e+00, 1.2138e+00, 1.3234e+00,\n",
      "        1.3511e+00, 1.4098e+00, 1.4773e+00, 1.5187e+00, 1.0331e-07, 1.1391e+00,\n",
      "        1.1538e+00, 1.1816e+00, 1.2598e+00, 1.3735e+00, 1.4022e+00, 1.4631e+00,\n",
      "        1.5332e+00, 1.5761e+00, 1.0939e-07, 1.2062e+00, 1.2218e+00, 1.2512e+00,\n",
      "        1.3340e+00, 1.4544e+00, 1.4848e+00, 1.5493e+00, 1.6235e+00, 1.6690e+00,\n",
      "        1.1205e-07, 1.2355e+00, 1.2514e+00, 1.2816e+00, 1.3664e+00, 1.4897e+00,\n",
      "        1.5209e+00, 1.5869e+00, 1.6629e+00, 1.7095e+00, 1.1458e-07, 1.2634e+00,\n",
      "        1.2797e+00, 1.3106e+00, 1.3972e+00, 1.5234e+00, 1.5552e+00, 1.6228e+00,\n",
      "        1.7005e+00, 1.7481e+00, 1.1736e-07, 1.2940e+00, 1.3107e+00, 1.3423e+00,\n",
      "        1.4311e+00, 1.5603e+00, 1.5929e+00, 1.6621e+00, 1.7417e+00, 1.7905e+00,\n",
      "        1.2184e-07, 1.3435e+00, 1.3608e+00, 1.3936e+00, 1.4858e+00, 1.6200e+00,\n",
      "        1.6538e+00, 1.7256e+00, 1.8083e+00, 1.8589e+00, 1.2847e-07, 1.4165e+00,\n",
      "        1.4348e+00, 1.4694e+00, 1.5666e+00, 1.7080e+00, 1.7437e+00, 1.8194e+00,\n",
      "        1.9066e+00, 1.9600e+00, 1.3604e-07, 1.5000e+00, 1.5194e+00, 1.5560e+00,\n",
      "        1.6589e+00, 1.8087e+00, 1.8465e+00, 1.9267e+00, 2.0190e+00, 2.0755e+00,\n",
      "        1.3795e-07, 1.5211e+00, 1.5407e+00, 1.5778e+00, 1.6822e+00, 1.8341e+00,\n",
      "        1.8724e+00, 1.9537e+00, 2.0473e+00, 2.1046e+00, 1.4402e-07, 1.5880e+00,\n",
      "        1.6085e+00, 1.6473e+00, 1.7562e+00, 1.9148e+00, 1.9548e+00, 2.0397e+00,\n",
      "        2.1374e+00, 2.1972e+00, 1.4606e-07, 1.6105e+00, 1.6313e+00, 1.6706e+00,\n",
      "        1.7811e+00, 1.9420e+00, 1.9825e+00, 2.0686e+00, 2.1677e+00, 2.2284e+00,\n",
      "        1.5793e-07, 1.7413e+00, 1.7638e+00, 1.8063e+00, 1.9258e+00, 2.0997e+00,\n",
      "        2.1436e+00, 2.2367e+00, 2.3438e+00, 2.4094e+00, 1.7080e-07, 1.8832e+00,\n",
      "        1.9075e+00, 1.9536e+00, 2.0828e+00, 2.2708e+00, 2.3183e+00, 2.4189e+00,\n",
      "        2.5348e+00, 2.6058e+00, 1.7827e-07, 1.9656e+00, 1.9910e+00, 2.0390e+00,\n",
      "        2.1739e+00, 2.3701e+00, 2.4197e+00, 2.5247e+00, 2.6457e+00, 2.7198e+00,\n",
      "        1.8682e-07, 2.0599e+00, 2.0865e+00, 2.1368e+00, 2.2781e+00, 2.4838e+00,\n",
      "        2.5357e+00, 2.6458e+00, 2.7726e+00, 2.8502e+00, 1.9709e-07, 2.1732e+00,\n",
      "        2.2012e+00, 2.2543e+00, 2.4034e+00, 2.6204e+00, 2.6752e+00, 2.7914e+00,\n",
      "        2.9251e+00, 3.0070e+00, 2.0015e-07, 2.2069e+00, 2.2354e+00, 2.2893e+00,\n",
      "        2.4408e+00, 2.6611e+00, 2.7167e+00, 2.8347e+00, 2.9705e+00, 3.0537e+00,\n",
      "        2.0819e-07, 2.2955e+00, 2.3251e+00, 2.3812e+00, 2.5387e+00, 2.7679e+00,\n",
      "        2.8258e+00, 2.9485e+00, 3.0897e+00, 3.1762e+00, 2.4805e-07, 2.7350e+00,\n",
      "        2.7703e+00, 2.8372e+00, 3.0248e+00, 3.2979e+00, 3.3668e+00, 3.5130e+00,\n",
      "        3.6813e+00, 3.7844e+00, 2.5151e-07, 2.7732e+00, 2.8090e+00, 2.8768e+00,\n",
      "        3.0670e+00, 3.3439e+00, 3.4138e+00, 3.5621e+00, 3.7327e+00, 3.8372e+00,\n",
      "        2.5536e-07, 2.8156e+00, 2.8520e+00, 2.9208e+00, 3.1140e+00, 3.3951e+00,\n",
      "        3.4660e+00, 3.6166e+00, 3.7898e+00, 3.8959e+00, 2.7385e-07, 3.0195e+00,\n",
      "        3.0585e+00, 3.1323e+00, 3.3394e+00, 3.6409e+00, 3.7170e+00, 3.8784e+00,\n",
      "        4.0642e+00, 4.1780e+00, 2.9155e-07, 3.2147e+00, 3.2562e+00, 3.3347e+00,\n",
      "        3.5553e+00, 3.8763e+00, 3.9573e+00, 4.1291e+00, 4.3269e+00, 4.4481e+00,\n",
      "        3.1860e-07, 3.5129e+00, 3.5583e+00, 3.6441e+00, 3.8851e+00, 4.2359e+00,\n",
      "        4.3244e+00, 4.5122e+00, 4.7284e+00, 4.8607e+00, 3.2941e-07, 3.6322e+00,\n",
      "        3.6790e+00, 3.7678e+00, 4.0170e+00, 4.3797e+00, 4.4712e+00, 4.6654e+00,\n",
      "        4.8888e+00, 5.0257e+00, 3.3268e-07, 3.6682e+00, 3.7155e+00, 3.8052e+00,\n",
      "        4.0569e+00, 4.4232e+00, 4.5156e+00, 4.7117e+00, 4.9374e+00, 5.0756e+00,\n",
      "        3.7632e-07, 4.1494e+00, 4.2029e+00, 4.3043e+00, 4.5890e+00, 5.0034e+00,\n",
      "        5.1079e+00, 5.3297e+00, 5.5850e+00, 5.7414e+00, 4.1872e-07, 4.6169e+00,\n",
      "        4.6764e+00, 4.7893e+00, 5.1060e+00, 5.5670e+00, 5.6833e+00, 5.9302e+00,\n",
      "        6.2142e+00, 6.3882e+00, 4.4625e-07, 4.9205e+00, 4.9839e+00, 5.1042e+00,\n",
      "        5.4418e+00, 5.9331e+00, 6.0571e+00, 6.3201e+00, 6.6228e+00, 6.8083e+00,\n",
      "        4.7980e-07, 5.2904e+00, 5.3586e+00, 5.4879e+00, 5.8509e+00, 6.3791e+00,\n",
      "        6.5124e+00, 6.7952e+00, 7.1207e+00, 7.3201e+00, 5.6168e-07, 6.1932e+00,\n",
      "        6.2731e+00, 6.4245e+00, 6.8494e+00, 7.4678e+00, 7.6238e+00, 7.9549e+00,\n",
      "        8.3360e+00, 8.5694e+00, 5.7984e-07, 6.3935e+00, 6.4760e+00, 6.6322e+00,\n",
      "        7.0708e+00, 7.7093e+00, 7.8703e+00, 8.2121e+00, 8.6055e+00, 8.8465e+00,\n",
      "        6.3611e-07, 7.0139e+00, 7.1044e+00, 7.2758e+00, 7.7570e+00, 8.4574e+00,\n",
      "        8.6341e+00, 9.0090e+00, 9.4406e+00, 9.7049e+00, 6.8726e-07, 7.5779e+00,\n",
      "        7.6757e+00, 7.8609e+00, 8.3808e+00, 9.1375e+00, 9.3284e+00, 9.7335e+00,\n",
      "        1.0200e+01, 1.0485e+01, 8.1772e-07, 9.0164e+00, 9.1327e+00, 9.3531e+00,\n",
      "        9.9716e+00, 1.0872e+01, 1.1099e+01, 1.1581e+01, 1.2136e+01, 1.2476e+01,\n",
      "        9.3546e-07, 1.0315e+01, 1.0448e+01, 1.0700e+01, 1.1407e+01, 1.2437e+01,\n",
      "        1.2697e+01, 1.3249e+01, 1.3883e+01, 1.4272e+01, 1.0018e-06, 1.1046e+01,\n",
      "        1.1188e+01, 1.1458e+01, 1.2216e+01, 1.3319e+01, 1.3597e+01, 1.4188e+01,\n",
      "        1.4867e+01, 1.5284e+01, 1.1517e-06, 1.2699e+01, 1.2863e+01, 1.3173e+01,\n",
      "        1.4045e+01, 1.5313e+01, 1.5633e+01, 1.6312e+01, 1.7093e+01, 1.7571e+01,\n",
      "        1.2081e-06, 1.3321e+01, 1.3492e+01, 1.3818e+01, 1.4732e+01, 1.6062e+01,\n",
      "        1.6398e+01, 1.7110e+01, 1.7929e+01, 1.8431e+01, 1.2516e-06, 1.3801e+01,\n",
      "        1.3979e+01, 1.4316e+01, 1.5263e+01, 1.6641e+01, 1.6989e+01, 1.7727e+01,\n",
      "        1.8576e+01, 1.9096e+01, 1.9101e-06, 2.1061e+01, 2.1333e+01, 2.1848e+01,\n",
      "        2.3292e+01, 2.5396e+01, 2.5926e+01, 2.7052e+01, 2.8348e+01, 2.9142e+01,\n",
      "        2.3595e-06, 2.6016e+01, 2.6352e+01, 2.6988e+01, 2.8772e+01, 3.1370e+01,\n",
      "        3.2026e+01, 3.3417e+01, 3.5017e+01, 3.5998e+01, 6.1995e-05, 6.8357e+02,\n",
      "        6.9239e+02, 7.0909e+02, 7.5599e+02, 8.2425e+02, 8.4147e+02, 8.7801e+02,\n",
      "        9.2007e+02, 9.4583e+02])}}\n"
     ]
    }
   ],
   "source": [
    "G_list = influence._compute_EKFAC_params(n_samples=3)\n",
    "print(G_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influences = influence.influence(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('img_proc_proj0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f16748fa5b9c7c97742513131751f6102eff5e936588c180718494a87f90c77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
